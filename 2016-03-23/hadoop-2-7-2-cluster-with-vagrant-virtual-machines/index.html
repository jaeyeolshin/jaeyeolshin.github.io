<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> 가상 머신으로 Hadoop-2.7.2 클러스터 구성하기 · 어쩌다 프로그래머</title><meta name="description" content="가상 머신으로 Hadoop-2.7.2 클러스터 구성하기 - Jaeyeol Shin"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="short icon" href="/favicon.png"><link rel="stylesheet" href="/css/apollo.css"><link rel="search" type="application/opensearchdescription+xml" href="http://yoursite.com/atom.xml" title="어쩌다 프로그래머"></head><body><div class="wrap"><header><a href="/" class="logo-link"><img src="/favicon.png"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="/atom.xml" target="_self" class="nav-list-link">RSS</a></li></ul></header><section class="container"><div class="post"><article class="post-block"><h1 class="post-title">가상 머신으로 Hadoop-2.7.2 클러스터 구성하기</h1><div class="post-info">Mar 23, 2016</div><div class="post-content"><p>부서 배치를 받고 일주일, 말로만 듣던 하둡을 만져 볼 기회가 찾아왔다. 나는 기술 교육 기간동안 일찍 출근하던 습관이 몸에 배어서 지금도 규정 출근 시각보다 30~40분 정도 일찍 회사에 도착한다.(평생 그런 적이 없었는데 이번에 이직을 하면서 그런 인간이 되었다.) 일찍 일어나는 새가 벌레를 잡듯, 일찍 출근하니 일찍 출근하시는 이사님께서 과제를 주셨다 ㅎㅎㅎ 이사님께 받은 과제가 바로 가상 머신을 이용하여 하둡 클러스터 구성하기이다. <a id="more"></a></p>
<h1 id="가상-머신-준비"><a href="#가상-머신-준비" class="headerlink" title="가상 머신 준비"></a>가상 머신 준비</h1><p><a href="https://www.vagrantup.com/" target="_blank" rel="external">Vagrant</a> 를 이용하면 편리하게 여러 대의 가상 머신을 생성할 수 있다. <a href="https://www.vagrantup.com/" target="_blank" rel="external">Vagrant</a> 가 편리하긴 하지만 역시 공짜는 없다. 배워야 한다. 그래도 한번 배워두면 두고두고 편리하게 이용할 수 있으니 직접 가상 머신을 생성하고 띄우는 것 보다는 낫다.</p>
<p>VirtualBox가 설치되어 있으면 다음과 같은 <a href="https://www.vagrantup.com/" target="_blank" rel="external">Vagrant</a> 명령어로 CentOS-6.5 가상 머신을 띄울 수 있다.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ vagrant init puphpet/centos65-x64; vagrant up --provider virtualbox</div></pre></td></tr></table></figure>
<p><code>puphpet/centos65-x64</code> 은 <a href="https://atlas.hashicorp.com/boxes/search" target="_blank" rel="external">Vagrant Boxes</a>에서 찾은 CentOS-6.5 이미지이다. 우분투나 여타 다른 OS 이미지도 여기서 찾아서 사용할 수 있다. <code>vagrant init</code> 명령어를 사용하면 명령어를 실행한 위치에 <code>.vagrant/</code> 디렉터리와 <code>Vagrantfile</code> 이라는 설정 파일이 생성된다.</p>
<p><a href="https://www.vagrantup.com/" target="_blank" rel="external">Vagrant</a> 를 배우는 것은 결국 이 설정 파일을 구성하는 법을 배우는 것이다. 설정 파일은 <a href="https://www.ruby-lang.org/ko/" target="_blank" rel="external">Ruby</a> 의 문법을 따른다. 알고보니 <a href="https://www.vagrantup.com/" target="_blank" rel="external">Vagrant</a> 도 <a href="https://www.ruby-lang.org/ko/" target="_blank" rel="external">Ruby</a> 로 작성된 프로젝트였다.(시간나면 배워야겠다.)</p>
<p>나의 목적은 여러 대의 가상 머신으로 하둡 클러스터를 구성하는 것이므로 한 번에 여러 대의 머신을 띄워야 한다. <a href="https://www.vagrantup.com/" target="_blank" rel="external">Vagrant</a> 도 이제 막 써보는 단계이고, <a href="https://www.ruby-lang.org/ko/" target="_blank" rel="external">Ruby</a> 도 몰라서 어떻게 하면 되는지 구글에게 물어봤다. 결국 다음과 같은 구성을 얻게 되었다.</p>
<figure class="highlight ruby"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div></pre></td><td class="code"><pre><div class="line">boxes = [</div><div class="line">  &#123;</div><div class="line">    <span class="symbol">:name</span> =&gt; <span class="string">"master"</span>,</div><div class="line">    <span class="symbol">:eth1</span> =&gt; <span class="string">"192.168.33.10"</span>,</div><div class="line">    <span class="symbol">:mem</span> =&gt; <span class="string">"512"</span>,</div><div class="line">    <span class="symbol">:cpu</span> =&gt; <span class="string">"1"</span>,</div><div class="line">    <span class="symbol">:ssh_port</span> =&gt; <span class="string">"2260"</span></div><div class="line">  &#125;,</div><div class="line">  &#123;</div><div class="line">    <span class="symbol">:name</span> =&gt; <span class="string">"slave1"</span>,</div><div class="line">    <span class="symbol">:eth1</span> =&gt; <span class="string">"192.168.33.12"</span>,</div><div class="line">    <span class="symbol">:mem</span> =&gt; <span class="string">"512"</span>,</div><div class="line">    <span class="symbol">:cpu</span> =&gt; <span class="string">"1"</span>,</div><div class="line">    <span class="symbol">:ssh_port</span> =&gt; <span class="string">"2280"</span></div><div class="line">  &#125;,</div><div class="line">  &#123;</div><div class="line">    <span class="symbol">:name</span> =&gt; <span class="string">"slave2"</span>,</div><div class="line">    <span class="symbol">:eth1</span> =&gt; <span class="string">"192.168.33.13"</span>,</div><div class="line">    <span class="symbol">:mem</span> =&gt; <span class="string">"512"</span>,</div><div class="line">    <span class="symbol">:cpu</span> =&gt; <span class="string">"1"</span>,</div><div class="line">    <span class="symbol">:ssh_port</span> =&gt; <span class="string">"2290"</span></div><div class="line">  &#125;</div><div class="line">]</div><div class="line"></div><div class="line">Vagrant.configure(<span class="number">2</span>) <span class="keyword">do</span> <span class="params">|config|</span></div><div class="line">  config.vm.box = <span class="string">"puphpet/centos65-x64"</span></div><div class="line"></div><div class="line">  config.vm.provider <span class="string">"virtualbox"</span> <span class="keyword">do</span> <span class="params">|v, override|</span></div><div class="line">    override.vm.box = <span class="string">"puphpet/centos65-x64"</span></div><div class="line">  <span class="keyword">end</span></div><div class="line"></div><div class="line">  boxes.each <span class="keyword">do</span> <span class="params">|opts|</span></div><div class="line">    config.vm.define opts[<span class="symbol">:name</span>] <span class="keyword">do</span> <span class="params">|config|</span></div><div class="line">      config.vm.hostname = opts[<span class="symbol">:name</span>]</div><div class="line"></div><div class="line">      config.vm.provider <span class="string">"virtualbox"</span> <span class="keyword">do</span> <span class="params">|v|</span></div><div class="line">        v.customize [<span class="string">"modifyvm"</span>, <span class="symbol">:id</span>, <span class="string">"--memory"</span>, opts[<span class="symbol">:mem</span>]]</div><div class="line">        v.customize [<span class="string">"modifyvm"</span>, <span class="symbol">:id</span>, <span class="string">"--cpus"</span>, opts[<span class="symbol">:cpu</span>]]</div><div class="line">      <span class="keyword">end</span></div><div class="line"></div><div class="line">      config.vm.network <span class="symbol">:private_network</span>, <span class="symbol">ip:</span> opts[<span class="symbol">:eth1</span>]</div><div class="line">      config.vm.network <span class="string">"forwarded_port"</span>, <span class="symbol">guest:</span> <span class="number">22</span>, <span class="symbol">host:</span> opts[<span class="symbol">:ssh_port</span>], <span class="symbol">id:</span> <span class="string">"ssh"</span>, <span class="symbol">auto_correct:</span> <span class="literal">true</span></div><div class="line"></div><div class="line">      config.ssh.port = opts[<span class="symbol">:ssh_port</span>]</div><div class="line">    <span class="keyword">end</span></div><div class="line">  <span class="keyword">end</span></div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure>
<p><code>puphpet/centos65-x64</code> 이미지로 서버를 만들면 vagrant 계정이 만들어진다. 비밀번호는 vagrant이고 이 계정으로 <code>sudo</code> 명령어를 수행할 수 있다. 이렇게 구성을 마치고 <code>$ vagrant up</code> 명령어를 수행하면 가상 머신 세 대가 생성되고 실행된다. 각 머신은 hadoop에서 다음 역할을 수행한다.</p>
<p><strong>master: namenode</strong><br><strong>slave1: datanode</strong><br><strong>slave2: datanode</strong></p>
<p>그럼 이제 하둡 클러스터를 구성해보자.</p>
<h1 id="준비-사항-모든-머신"><a href="#준비-사항-모든-머신" class="headerlink" title="준비 사항(모든 머신)"></a>준비 사항(모든 머신)</h1><p>ssh, sshd, rsync, java를 설치해야 한다. ssh, sshd는 CentOS-6.5에 포함되어 있으므로 java만 설치하도록 하자.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ sudo yum install -y java-1.7.0-openjdk-devel</div></pre></td></tr></table></figure>
<p>하둡은 $JAVA_HOME 변수를 참조한다. 나는 <code>/etc/profile.d/hadoop.sh</code> 에서 $JAVA_HOME 변수를 export 하도록 하였다. 하둡은 IPv6 network를 지원하지 않는다. 두번째 변수는 IPv4를 사용하도록 java 파라미터를 넣어준다. 마지막 줄에서는 hadoop 설정 파일의 위치를 지정해준다.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span> [ <span class="string">"<span class="variable">$JAVA_HOME</span>"</span> = <span class="string">""</span> ]</div><div class="line"><span class="keyword">then</span></div><div class="line">    <span class="built_in">export</span> JAVA_HOME=/usr/lib/jvm/java-1.7.0-openjdk-1.7.0.95.x86_64</div><div class="line"><span class="keyword">fi</span></div><div class="line"></div><div class="line"><span class="keyword">if</span> [ <span class="string">"<span class="variable">$HADOOP_OPTS</span>"</span> = <span class="string">""</span> ]</div><div class="line"><span class="keyword">then</span></div><div class="line">    <span class="built_in">export</span> HADOOP_OPTS=-Djava.net.preferIPv4Stack=<span class="literal">true</span></div><div class="line"><span class="keyword">fi</span></div><div class="line"></div><div class="line"><span class="keyword">if</span> [ <span class="string">"<span class="variable">$HADOOP_CONF_DIR</span>"</span> = <span class="string">""</span> ]</div><div class="line"><span class="keyword">then</span></div><div class="line">    <span class="built_in">export</span> HADOOP_CONF_DIR=/opt/hadoop/hadoop/etc/hadoop</div><div class="line"><span class="keyword">fi</span></div></pre></td></tr></table></figure>
<h1 id="계정-생성-모든-머신"><a href="#계정-생성-모든-머신" class="headerlink" title="계정 생성(모든 머신)"></a>계정 생성(모든 머신)</h1><p>hadoop을 실행할 계정을 만들자(계정 이름이 hadoop이 아니어도 된다.)</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ sudo useradd hadoop</div><div class="line">$ sudo passwd hadoop</div></pre></td></tr></table></figure>
<h1 id="서버간-ssh-접속-설정-모든-머신"><a href="#서버간-ssh-접속-설정-모든-머신" class="headerlink" title="서버간 ssh 접속 설정(모든 머신)"></a>서버간 ssh 접속 설정(모든 머신)</h1><p>서버간 비밀번호 입력없이 ssh 접속을 할 수 있게 설정해야 한다. 우선 서버끼리 이름으로 접속할 수 있도록 <code>/etc/hosts</code> 파일을 수정하자.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">192.168.33.10 master</div><div class="line">192.168.33.11 secondary</div><div class="line">192.168.33.12 slave1</div><div class="line">192.168.33.13 slave2</div></pre></td></tr></table></figure>
<p>호스트 파일(ex. master 머신)에 <code>127.0.0.1 master localhost ...</code> 이런 내용이 있을 수 있다. <code>127.0.0.1 master</code> 는 나중에 문제가 될 수 있으므로 <code>127.0.0.1 master</code>는 지워주자. <code>127.0.0.1 localhost</code> 는 지우지 않아도 된다. 아니면 마음 편히 기존에 있던 내용은 다 지우고 위와 같이 설정해줘도 된다.</p>
<p><code>/etc/hosts</code> 파일 설정이 완료되었으면 1에서 생성한 계정으로 바꾸어 서버마다 key를 생성하고 공유해줘야 한다.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">$ su hadoop</div><div class="line">$ ssh-keygen -t rsa</div><div class="line">$ ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@master</div><div class="line">$ ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@slave1</div><div class="line">$ ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@slave2</div><div class="line">$ chmod 0600 ~/.ssh/authorized_keys</div><div class="line">$ <span class="built_in">exit</span></div></pre></td></tr></table></figure>
<p><strong>※ 자기 자신도 ssh로 접속할 수 있도록 모든 머신에 위 명령어를 실행해야 한다.</strong></p>
<h1 id="Hadoop-2-7-2-설치-master만"><a href="#Hadoop-2-7-2-설치-master만" class="headerlink" title="Hadoop-2.7.2 설치(master만)"></a>Hadoop-2.7.2 설치(master만)</h1><p>이제 하둡을 설치해 보자. 설치 경로는 달라도 상관 없다.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">$ sudo mkdir /opt/hadoop</div><div class="line">$ <span class="built_in">cd</span> /opt/hadoop/</div><div class="line">$ sudo wget http://apache.mirror.cdnetworks.com/hadoop/common/hadoop-2.7.2/hadoop-2.7.2.tar.gz</div><div class="line">$ sudo tar -xzf hadoop-2.7.2.tar.gz</div><div class="line">$ sudo mv hadoop-1.2.0 hadoop</div><div class="line">$ sudo chown -R hadoop /opt/hadoop</div><div class="line">$ <span class="built_in">cd</span> /opt/hadoop/hadoop/</div></pre></td></tr></table></figure>
<h1 id="Hadoop-공통-설정-master만"><a href="#Hadoop-공통-설정-master만" class="headerlink" title="Hadoop 공통 설정(master만)"></a>Hadoop 공통 설정(master만)</h1><p><strong><code>core-site.xml</code></strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$ su hadoop</div><div class="line">$ <span class="built_in">cd</span> /opt/hadoop/hadoop</div><div class="line">$ vi etc/hadoop/core-site.xml</div></pre></td></tr></table></figure>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://master:9000/<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.permissions<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></div></pre></td></tr></table></figure>
<p><strong><code>hdfs-site.xml</code></strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ vi etc/hadoop/hdfs-site.xml</div></pre></td></tr></table></figure>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"></div><div class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/hadoop/hadoop/hdfs/namenode<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"></div><div class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/hadoop/hadoop/hdfs/datanode<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></div></pre></td></tr></table></figure>
<p><strong><code>yarn-site.xml</code></strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ vi etc/hadoop/yarn-site.xml</div></pre></td></tr></table></figure>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.scheduler.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>master:8030<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>master:8032<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>master:8088<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.resource-tracker.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>master:8031<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.admin.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>master:8033<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></div></pre></td></tr></table></figure>
<p>여기까지 하고 설치한 하둡 디렉터리 통째로 slave1, slave2에 복사해주자.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$ <span class="built_in">cd</span> /opt/hadoop</div><div class="line">$ scp -r hadoop hadoop-slave-1:/opt/hadoop</div><div class="line">$ scp -r hadoop hadoop-slave-2:/opt/hadoop</div></pre></td></tr></table></figure>
<h1 id="Hadoop-마스터-설정-master만"><a href="#Hadoop-마스터-설정-master만" class="headerlink" title="Hadoop 마스터 설정(master만)"></a>Hadoop 마스터 설정(master만)</h1><p>4에서 설정한 파일들은 master 머신에서만 수정을 하긴 했지만 namenode든 datanode든 공통적으로 필요한 내용이라 설정한 내용을 모두 slave1, slave2에 복사하였다. 이제는 master에 필요한 설정을 해주자.</p>
<p><strong><code>mapred-site.xml</code></strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ vi etc/hadoop/mapred-site.xml</div></pre></td></tr></table></figure>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobtracker.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>master:9001<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></div></pre></td></tr></table></figure>
<p><strong><code>slave</code></strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ vi etc/hadoop/slave</div></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">slave1</div><div class="line">slave2</div></pre></td></tr></table></figure>
<h1 id="하둡-클러스터-구동-master만"><a href="#하둡-클러스터-구동-master만" class="headerlink" title="하둡 클러스터 구동(master만)"></a>하둡 클러스터 구동(master만)</h1><p><strong>Namenode 포맷</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ bin/hdfs namenode -format</div></pre></td></tr></table></figure>
<p><strong>Distributed Format System 시작</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ sbin/start-dfs.sh</div></pre></td></tr></table></figure>
<p><strong>YARN MapReduce Job Tracker 시작</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ sbin/start-yarn.sh</div></pre></td></tr></table></figure>
<h1 id="동작-확인"><a href="#동작-확인" class="headerlink" title="동작 확인"></a>동작 확인</h1><p>PC에서 <a href="http://192.168.33.10:50070" target="_blank" rel="external">http://192.168.33.10:50070</a> 으로 정상적으로 접속되는지 확인해보자. Namenode와 Datanode가 정상적으로 연동 된다면 <code>Live Nodes</code> 라는 칸에 Datanode의 개수 2가 표시된다.</p>
<h2 id="WordCount-예제-실행"><a href="#WordCount-예제-실행" class="headerlink" title="WordCount 예제 실행"></a>WordCount 예제 실행</h2><p><a href="https://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html" target="_blank" rel="external">WordCount</a>는 프로그래밍 기초로 치면 “Hello, World” 예제라고 볼 수 있다. 링크를 따라가 예제를 실행해보자.</p>
<p>다음과 같은 결과를 얻는다면 성공이다.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">$ bin/hadoop fs -cat /user/hadoop/wordcount/output/*</div><div class="line">Bye 1</div><div class="line">Goodbye 1</div><div class="line">Hadoop 2</div><div class="line">Hello 2</div><div class="line">World 2</div></pre></td></tr></table></figure>
<p>위에 내가 적어둔대로 한다고 100% 하둡 클러스터가 문제없이 동작할 것이라는 보장은 없다. 아마 제대로 동작하지 않을 확률이 더 높을 것이다. 내가 쓴 글이 잘못되었을 수도 있고, 따라하는 과정에서 실수가 있을 수 있다. 나도 여러 튜토리얼을 보고 따라했지만 그대로 되진 않았다. 하둡 클러스터를 구성하면서 배운 점은 잘 안되면 무조건 로그를 봐야 한다는 것이다. 나는 이 클러스터를 구성하는데 이틀이 걸렸다. <code>jps</code> 를 쳐보면 namenode의 프로세스도 잘 떠있고, datanode의 프로세스도 잘 떠 있는데도 namenode에서 datanode를 인식하지 못했다. 답답한 마음에 구글님께 여쭤봤지만 같은 문제라도 원인은 천차만별이었다. 결국 로그를 뒤져보니 datanode에서 namenode로 연결이 안되는 문제였다. 이 문제는 namenode의 <code>/etc/hosts</code> 파일의 127.0.0.1 master를 지우면서 해결되었다. 클러스터 구성에 문제가 생겼다면 구글에게 물어보기 전에 로그를 한 번 열어보자 :)</p>
<h1 id="참고"><a href="#참고" class="headerlink" title="참고"></a>참고</h1><p><a href="https://chawlasumit.wordpress.com/2015/03/09/install-a-multi-node-hadoop-cluster-on-ubuntu-14-04/" target="_blank" rel="external">https://chawlasumit.wordpress.com/2015/03/09/install-a-multi-node-hadoop-cluster-on-ubuntu-14-04/</a><br><a href="http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/SingleCluster.html" target="_blank" rel="external">http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/SingleCluster.html</a><br><a href="http://mudchobo.tistory.com/541" target="_blank" rel="external">http://mudchobo.tistory.com/541</a></p>
</div></article></div></section><footer><div class="paginator"><a href="/2017-04-19/java8-changes-in-interface/" class="prev">PREV</a><a href="/2016-03-13/training-test/" class="next">NEXT</a></div><div id="disqus_thread"></div><script>var disqus_shortname = 'jaeyeolshingithubio';
var disqus_identifier = '2016-03-23/hadoop-2-7-2-cluster-with-vagrant-virtual-machines/';
var disqus_title = '가상 머신으로 Hadoop-2.7.2 클러스터 구성하기';
var disqus_url = 'http://yoursite.com/2016-03-23/hadoop-2-7-2-cluster-with-vagrant-virtual-machines/';
(function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();</script><script id="dsq-count-scr" src="//jaeyeolshingithubio.disqus.com/count.js" async></script><div class="copyright"><p>© 2016 - 2017 <a href="http://yoursite.com">Jaeyeol Shin</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/pinggod/hexo-theme-apollo" target="_blank">hexo-theme-apollo</a>.</p></div></footer></div><script async src="//cdn.bootcss.com/mathjax/2.6.1/MathJax.js?config=TeX-MML-AM_CHTML"></script><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create',"UA-72209766-1",'auto');ga('send','pageview');</script></body></html>